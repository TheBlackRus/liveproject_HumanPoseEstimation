{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "liveproject_humanpose_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVtuUbP8+xUJxQL3VrAgtO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBlackRus/liveproject_HumanPoseEstimation/blob/master/liveproject_humanpose_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZt0Cu4vpfJ",
        "colab_type": "text"
      },
      "source": [
        "Welcome to part 2. Training of a CNN wiht pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZEqBpQ4ve--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "#!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k75c3tbK1K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WOsEzDPygqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class SVHN_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        # Transform data to Torch Tensors\n",
        "        self.images = torch.tensor(data['X']).permute([3,2,0,1])\n",
        "        self.labels = torch.tensor(data['y'])\n",
        "        self.size = self.labels.shape[0]\n",
        "\n",
        "        # replace label 10 with label 0\n",
        "        self.labels[np.where(self.labels == 10)] = 0\n",
        "\n",
        "        # convert to float and normalize images to 0..1 range\n",
        "        self.images = self.images.to(dtype=torch.float)\n",
        "        self.images = self.images / 255.0\n",
        "\n",
        "        self.labels = self.labels.to(dtype=torch.long)\n",
        "\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVTN1efYzPhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = loadmat('train_32x32.mat')\n",
        "test_data = loadmat('test_32x32.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e97xHxSxzcDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = SVHN_dataset(train_data)\n",
        "test_dataset = SVHN_dataset(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWt77OcX3FZb",
        "colab_type": "text"
      },
      "source": [
        "Values are supposed to be normalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq1vvK1Ezvg-",
        "colab_type": "code",
        "outputId": "c3400c43-320d-401a-a11a-d0c143e88b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"images range [\", train_dataset.images.min(),\",\", train_dataset.images.max(),\"]\",train_dataset.images.shape)\n",
        "print(\"labels\",train_dataset.labels.unique())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images range [ tensor(0.) , tensor(1.) ] torch.Size([73257, 3, 32, 32])\n",
            "labels tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZttWiWwszP3u",
        "colab_type": "text"
      },
      "source": [
        "Creating the net\n",
        "1. convolution, kernel_size=5, channels=6, stride=1, padding=2\n",
        "2. batch-normalization\n",
        "3. ReLU\n",
        "4. Max-pool, kernel_size=2, stride=2\n",
        "\n",
        "5. convolution, kernel_size=3, channels=12, stride=1, padding=1\n",
        "6. batch-normalization\n",
        "7. ReLU\n",
        "8. Max-pool, kernel_size=2, stride=2\n",
        "\n",
        "9. convolution, kernel_size=3, channels=24, stride=1, padding=1\n",
        "10. batch-normalization\n",
        "11. ReLU\n",
        "12. Max-pool, kernel_size=2, stride=2\n",
        "\n",
        "13. fully connected layer, output_size=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7cF7fFhH5H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6pedsjx4YXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #block\n",
        "        self.conv_1 = nn.Conv2d(in_channels = 3, out_channels=6,kernel_size=5,stride=1,padding=2)\n",
        "        #nn.init.normal_(self.conv_1.weight, std=0.001)\n",
        "        #nn.init.constant_(self.conv_1.bias,0)\n",
        "        self.batch_norm_1 = nn.BatchNorm2d(6) # same as out_channels before layer \n",
        "        self.relu_1 = nn.ReLU()\n",
        "        self.pool_1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        self.conv_2 = nn.Conv2d(in_channels = 6, out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #nn.init.normal_(self.conv_2.weight, std=0.001)\n",
        "        #nn.init.constant_(self.conv_2.bias,0)\n",
        "        self.batch_norm_2 = nn.BatchNorm2d(12) # same as out_channels before layer \n",
        "        self.relu_2 = nn.ReLU()\n",
        "        self.pool_2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv_3 = nn.Conv2d(in_channels= 12, out_channels=24,kernel_size=3,stride=1,padding=1)\n",
        "        #nn.init.normal_(self.conv_3.weight, std=0.001)\n",
        "        #nn.init.constant_(self.conv_3.bias,0)\n",
        "        self.batch_norm_3 = nn.BatchNorm2d(24) # same as out_channels before layer \n",
        "        self.relu_3 = nn.ReLU()\n",
        "        self.pool_3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(24 * 4 * 4, 10)# 24 chans x 32//(2*2*2)\n",
        "        #nn.init.normal_(self.fc1.weight, std=0.001)\n",
        "        #nn.init.constant_(self.fc1.bias,0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.batch_norm_1(x)\n",
        "        x = self.relu_1(x)\n",
        "        x = self.pool_1(x)\n",
        "\n",
        "        x = self.conv_2(x)\n",
        "        x = self.batch_norm_2(x)\n",
        "        x = self.relu_2(x)\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        x = self.conv_3(x)\n",
        "        x = self.batch_norm_3(x)\n",
        "        x = self.relu_3(x)\n",
        "        x = self.pool_3(x)\n",
        "\n",
        "        x = x.view(-1, 24 * 4 * 4)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        #x = F.relu(self.fc2(x))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net = Net()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_HVjaRrTm1X",
        "colab_type": "code",
        "outputId": "57237977-ff5a-4897-9780-fe50a5f89f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# import torchvision\n",
        "\"\"\"\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\"\"\"\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=False,\\n                                        download=True)\\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\\n                                          shuffle=True, num_workers=2)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MCj_4OKUogh",
        "colab_type": "text"
      },
      "source": [
        "Define Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK5TQM_VUwRE",
        "colab_type": "code",
        "outputId": "e56873ef-4f4f-455f-c710-4339cb5c4e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(),lr=0.01) # ,lr=0.001 #optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=256,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=256,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "\n",
        "\"\"\"\n",
        "trainloader.dataset.labels\n",
        "\"\"\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrainloader.dataset.labels\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPVTUpjBV2Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, dataloader):\n",
        "\n",
        "    model.eval()\n",
        "    # TODO: calculate accuracy\n",
        "    acc = 0\n",
        "    count = 0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels = data\n",
        "      labels = labels.squeeze()\n",
        "      inputs = inputs.cuda()\n",
        "      labels = labels.cuda()\n",
        "      \n",
        "      outputs = net(inputs)\n",
        "      predicted = torch.argmax(outputs, dim=1)\n",
        "      #print(predicted, labels)\n",
        "      acc = acc + (predicted == labels).sum()\n",
        "      count = count + labels.shape[0]\n",
        "    #print(\"AC\",acc,count)\n",
        "    acc = acc.to(torch.float)\n",
        "    \n",
        "    if count >0:\n",
        "      accuracy = acc/count\n",
        "    else:\n",
        "      accuracy = 0\n",
        "    #outputs = net(inputs)\n",
        "    model.train()\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePTpjMDIUvuo",
        "colab_type": "code",
        "outputId": "a4b66861-3b8d-4f5b-f03a-6e2d31891ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"device\",\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.cuda()\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        labels = labels.squeeze()\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        outputs.cuda()\n",
        "        #print(labels,labels.shape)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            acc = get_accuracy(net,testloader)\n",
        "            print(\"acc\" , acc)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device cuda\n",
            "[1,   100] loss: 0.105\n",
            "acc tensor(0.5869, device='cuda:0')\n",
            "[1,   200] loss: 0.043\n",
            "acc tensor(0.7606, device='cuda:0')\n",
            "[2,   100] loss: 0.026\n",
            "acc tensor(0.8374, device='cuda:0')\n",
            "[2,   200] loss: 0.024\n",
            "acc tensor(0.8478, device='cuda:0')\n",
            "[3,   100] loss: 0.022\n",
            "acc tensor(0.8573, device='cuda:0')\n",
            "[3,   200] loss: 0.021\n",
            "acc tensor(0.8584, device='cuda:0')\n",
            "[4,   100] loss: 0.019\n",
            "acc tensor(0.8520, device='cuda:0')\n",
            "[4,   200] loss: 0.020\n",
            "acc tensor(0.8709, device='cuda:0')\n",
            "[5,   100] loss: 0.019\n",
            "acc tensor(0.8424, device='cuda:0')\n",
            "[5,   200] loss: 0.019\n",
            "acc tensor(0.8612, device='cuda:0')\n",
            "[6,   100] loss: 0.018\n",
            "acc tensor(0.8592, device='cuda:0')\n",
            "[6,   200] loss: 0.018\n",
            "acc tensor(0.8632, device='cuda:0')\n",
            "[7,   100] loss: 0.017\n",
            "acc tensor(0.8470, device='cuda:0')\n",
            "[7,   200] loss: 0.017\n",
            "acc tensor(0.8817, device='cuda:0')\n",
            "[8,   100] loss: 0.017\n",
            "acc tensor(0.8695, device='cuda:0')\n",
            "[8,   200] loss: 0.017\n",
            "acc tensor(0.8598, device='cuda:0')\n",
            "[9,   100] loss: 0.017\n",
            "acc tensor(0.8728, device='cuda:0')\n",
            "[9,   200] loss: 0.017\n",
            "acc tensor(0.8741, device='cuda:0')\n",
            "[10,   100] loss: 0.016\n",
            "acc tensor(0.8692, device='cuda:0')\n",
            "[10,   200] loss: 0.016\n",
            "acc tensor(0.8623, device='cuda:0')\n",
            "[11,   100] loss: 0.016\n",
            "acc tensor(0.8732, device='cuda:0')\n",
            "[11,   200] loss: 0.017\n",
            "acc tensor(0.8709, device='cuda:0')\n",
            "[12,   100] loss: 0.016\n",
            "acc tensor(0.8561, device='cuda:0')\n",
            "[12,   200] loss: 0.016\n",
            "acc tensor(0.8754, device='cuda:0')\n",
            "[13,   100] loss: 0.015\n",
            "acc tensor(0.8704, device='cuda:0')\n",
            "[13,   200] loss: 0.016\n",
            "acc tensor(0.8652, device='cuda:0')\n",
            "[14,   100] loss: 0.015\n",
            "acc tensor(0.8738, device='cuda:0')\n",
            "[14,   200] loss: 0.016\n",
            "acc tensor(0.8639, device='cuda:0')\n",
            "[15,   100] loss: 0.015\n",
            "acc tensor(0.8836, device='cuda:0')\n",
            "[15,   200] loss: 0.016\n",
            "acc tensor(0.8774, device='cuda:0')\n",
            "[16,   100] loss: 0.015\n",
            "acc tensor(0.8604, device='cuda:0')\n",
            "[16,   200] loss: 0.016\n",
            "acc tensor(0.8797, device='cuda:0')\n",
            "[17,   100] loss: 0.015\n",
            "acc tensor(0.8735, device='cuda:0')\n",
            "[17,   200] loss: 0.016\n",
            "acc tensor(0.8814, device='cuda:0')\n",
            "[18,   100] loss: 0.015\n",
            "acc tensor(0.8776, device='cuda:0')\n",
            "[18,   200] loss: 0.015\n",
            "acc tensor(0.8846, device='cuda:0')\n",
            "[19,   100] loss: 0.015\n",
            "acc tensor(0.8772, device='cuda:0')\n",
            "[19,   200] loss: 0.016\n",
            "acc tensor(0.8793, device='cuda:0')\n",
            "[20,   100] loss: 0.015\n",
            "acc tensor(0.8750, device='cuda:0')\n",
            "[20,   200] loss: 0.015\n",
            "acc tensor(0.8750, device='cuda:0')\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vKv1kIQzBBL",
        "colab_type": "code",
        "outputId": "6a3ec71e-fac6-4c97-f50d-d9257a480867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_accuracy(net,testloader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8815, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq87Ihk6hPms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        #block\n",
        "        # in 32x32x3\n",
        "        self.conv_1 = nn.Conv2d(in_channels = 3, out_channels=32,kernel_size=5,stride=1,padding=2) # 32x32x6\n",
        "        self.batch_norm_1 = nn.BatchNorm2d(32) # same as out_channels before layer \n",
        "        self.relu_1 = nn.ReLU()\n",
        "        self.pool_1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv_2 = nn.Conv2d(in_channels = 32, out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.batch_norm_2 = nn.BatchNorm2d(32) # same as out_channels before layer \n",
        "        self.relu_2 = nn.ReLU()\n",
        "        self.pool_2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv_3 = nn.Conv2d(in_channels= 32, out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.batch_norm_3 = nn.BatchNorm2d(32) # same as out_channels before layer \n",
        "        self.relu_3 = nn.ReLU()\n",
        "        self.pool_3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 10)# 24 chans x 32//(2*2*2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.batch_norm_1(x)\n",
        "        x = self.relu_1(x)\n",
        "        x = self.pool_1(x)\n",
        "\n",
        "\n",
        "        # skip\n",
        "        s = x\n",
        "        x = self.conv_2(x)\n",
        "        x = self.batch_norm_2(x)\n",
        "        x = self.relu_2(x)\n",
        "        x = s + x\n",
        "        x = self.pool_2(x)\n",
        "\n",
        "        s= x\n",
        "        x = self.conv_3(x)\n",
        "        x = self.batch_norm_3(x)\n",
        "        x = self.relu_3(x)\n",
        "        x= s + x\n",
        "        x = self.pool_3(x)\n",
        "\n",
        "        x = x.view(-1, 32 * 4 * 4)\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        #x = F.relu(self.fc2(x))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = MyNet()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}