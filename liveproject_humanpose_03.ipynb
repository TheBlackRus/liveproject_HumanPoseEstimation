{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "liveproject_humanpose_03.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQhdtmgMSkGGgh5sj4dQL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70c7e45337e14bfebd68b1b0cbd5faca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56524ce3f1964d6b8824e38b440e2520",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c7c4c57c2d44c7bbec6525ec7b40bbd",
              "IPY_MODEL_8a4a6915f6fa4f339398dbff4a0e0e94"
            ]
          }
        },
        "56524ce3f1964d6b8824e38b440e2520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c7c4c57c2d44c7bbec6525ec7b40bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_327ebf630d214e54acdc3ffdccb3abfb",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 167502836,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 167502836,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a27f12f8c6b41e482afcb4d5cc7fbac"
          }
        },
        "8a4a6915f6fa4f339398dbff4a0e0e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5bb124af9c244e0833f0b0d1bd8a55b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 160M/160M [00:01&lt;00:00, 94.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65073495fd3947578a6519e79f6e8128"
          }
        },
        "327ebf630d214e54acdc3ffdccb3abfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a27f12f8c6b41e482afcb4d5cc7fbac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5bb124af9c244e0833f0b0d1bd8a55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65073495fd3947578a6519e79f6e8128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBlackRus/liveproject_HumanPoseEstimation/blob/master/liveproject_humanpose_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv5ZCKXna8nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzBNHRbvcT0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d4aabda3-745d-4e4d-bea7-0d61732a8a83"
      },
      "source": [
        "# This code downloads the coco dataset from Amazon S3 in parallel.\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "import multiprocessing\n",
        "import subprocess\n",
        "files = ['val2017.zip', 'annotations_trainval2017.zip']#, 'train2017.zip']\n",
        "\n",
        "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "def download_and_unzip_from_s3(file_name, bucket_name='fast-ai-coco'):\n",
        "    print(\"Downloading\", file_name)\n",
        "    s3.download_file(bucket_name, file_name, file_name)\n",
        "    print(\"Finished downloading\", file_name, \". Starting to unzip.\")\n",
        "    subprocess.run([\"unzip\", file_name])\n",
        "    print(\"Finished unzipping\", file_name)\n",
        "\n",
        "# Download in parallel\n",
        "num_cpus = multiprocessing.cpu_count()\n",
        "with multiprocessing.Pool(num_cpus) as p:\n",
        "    p.map(download_and_unzip_from_s3, files)\n",
        "\n",
        "print(\"Done transferring all datasets\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading val2017.zip\n",
            "Downloading annotations_trainval2017.zip\n",
            "Finished downloading annotations_trainval2017.zip . Starting to unzip.\n",
            "Finished downloading val2017.zip . Starting to unzip.\n",
            "Finished unzipping annotations_trainval2017.zip\n",
            "Finished unzipping val2017.zip\n",
            "Done transferring all datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR0OCQZmc6aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the meta data of the validation set\n",
        "import json\n",
        "file_name = \"annotations//person_keypoints_val2017.json\"\n",
        "with open(file_name, 'r') as json_raw:\n",
        "    meta = json.load(json_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_8527Tgc8ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = 0\n",
        "img_info = meta[\"images\"][example]\n",
        "img_annotation = meta[\"annotations\"][example]\n",
        "img_catogory = meta[\"categories\"][0][\"keypoints\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bFRWMnmc81f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c524e1f8-8e93-4aa8-80b8-2487bf0dcafa"
      },
      "source": [
        "img_file = str(img_annotation[\"image_id\"])\n",
        "img_file = img_file.zfill(12) +\".jpg\" #img_info[\"file_name\"]\n",
        "print(img_file, img_annotation[\"image_id\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "000000425226.jpg 425226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_sRoAwKc88H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(img, target_width=192, target_height=256):\n",
        "  img_resized = cv2.resize(img,(target_width,target_height))\n",
        "  return img_resized\n",
        "\n",
        "def crop_image(img, upper_left_corner, size):\n",
        "  start_x, start_y = upper_left_corner\n",
        "  w,h = size\n",
        "  img_cropped = img[int(start_y):(int(start_y+h)),int(start_x):int(start_x+w),:]\n",
        "  return img_cropped\n",
        "\n",
        "def adjust_keypoint(keypoint, start, scale):\n",
        "  keypoint_x, keypoint_y= keypoint\n",
        "  start_x,start_y = start\n",
        "  sx,sy = scale\n",
        "  x = (keypoint_x-start_x)*sx\n",
        "  y = (keypoint_y-start_y)*sy\n",
        "  return x,y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFecso9GdJ4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#from matplotlib.pyplot import imshow\n",
        "from matplotlib import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngZYVZL_dJ-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = image.imread(\"val2017//\"+img_file)\n",
        "img = img / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T--47incdKDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "223fcd8a-b99c-4271-8feb-e7f792d98008"
      },
      "source": [
        "img_batch = torch.Tensor([img, img])\n",
        "print(img_batch.shape)\n",
        "img_batch = img_batch.permute([0,3,2,1])\n",
        "img_batch.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 640, 480, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 480, 640])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5JajHMpdKHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_batch.max()\n",
        "img_batch = img_batch.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQR5V6EGbTEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70c7e45337e14bfebd68b1b0cbd5faca",
            "56524ce3f1964d6b8824e38b440e2520",
            "8c7c4c57c2d44c7bbec6525ec7b40bbd",
            "8a4a6915f6fa4f339398dbff4a0e0e94",
            "327ebf630d214e54acdc3ffdccb3abfb",
            "3a27f12f8c6b41e482afcb4d5cc7fbac",
            "a5bb124af9c244e0833f0b0d1bd8a55b",
            "65073495fd3947578a6519e79f6e8128"
          ]
        },
        "outputId": "5e4628a7-4e3b-4083-8de9-87f6ea132a61"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.cuda()\n",
        "model.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70c7e45337e14bfebd68b1b0cbd5faca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=167502836), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d()\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d()\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d()\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d()\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign()\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoFk-bJ6dKOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e44510b7-f02d-4aa9-818f-ce7cb0af87aa"
      },
      "source": [
        "y = model(img_batch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2QH16EicA_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e69b21c-1e9b-4b00-a38a-bbcdcfc70eba"
      },
      "source": [
        "y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'boxes': tensor([[212.5397,  64.2023, 563.9282, 358.7718],\n",
              "          [355.1589, 226.9010, 394.5103, 299.8187],\n",
              "          [389.6106,  89.7069, 565.4318, 280.4237],\n",
              "          [ 31.8342, 141.2249, 331.9860, 406.0846],\n",
              "          [505.8641, 118.0132, 577.4388, 238.9388],\n",
              "          [ 48.9423,  52.3993, 567.9708, 441.1093],\n",
              "          [269.1020, 288.9832, 305.5331, 314.1668],\n",
              "          [236.7639, 178.1634, 305.9442, 259.8866],\n",
              "          [227.3062, 120.0427, 242.7734, 138.9593],\n",
              "          [338.5215, 220.8336, 377.9923, 313.5775],\n",
              "          [187.0308,  13.4958, 254.0475,  83.2915],\n",
              "          [197.4345, 300.9328, 606.9046, 453.8034],\n",
              "          [365.9975, 226.3491, 393.0796, 276.2737],\n",
              "          [339.6570, 226.1735, 356.4973, 312.2776],\n",
              "          [296.6670, 292.5830, 333.8354, 310.4262],\n",
              "          [ 48.6918, 261.7969, 128.5480, 354.0468],\n",
              "          [ 64.2551,  53.7829, 594.8115, 415.7347],\n",
              "          [284.8063, 285.2485, 445.4222, 315.1196],\n",
              "          [232.7171, 141.9245, 239.5738, 164.5803],\n",
              "          [ 34.7142, 153.2637, 226.5622, 379.1881],\n",
              "          [470.8498, 388.5547, 492.6794, 422.2319],\n",
              "          [236.4508, 116.4599, 248.5372, 130.9023],\n",
              "          [239.7056,  92.6143, 249.2436, 109.9763],\n",
              "          [189.5545, 161.1655, 290.0090, 386.9644],\n",
              "          [188.5357, 238.6656, 606.9074, 457.8269],\n",
              "          [414.8325, 289.5162, 446.8152, 317.3776],\n",
              "          [364.6156, 284.5240, 428.0466, 315.6868],\n",
              "          [313.9790, 241.6604, 344.0585, 303.8826],\n",
              "          [313.2613, 242.8336, 342.6058, 299.2422],\n",
              "          [ 93.6444, 115.9924, 574.4103, 445.6391],\n",
              "          [ 78.5636, 211.0039, 108.7784, 248.1253],\n",
              "          [428.6737, 386.3780, 463.9395, 426.0912],\n",
              "          [376.0112,  82.6038, 554.4664, 294.0862],\n",
              "          [390.5019,  86.7960, 556.5341, 296.4944],\n",
              "          [466.5657, 104.2762, 579.8484, 279.6210],\n",
              "          [270.7242, 288.7029, 306.7976, 303.0364],\n",
              "          [451.9509, 427.8454, 516.2504, 467.8262],\n",
              "          [231.8021, 103.0909, 458.8400, 315.9155],\n",
              "          [237.7713, 113.1714, 248.8435, 138.4678],\n",
              "          [351.7283, 285.5481, 373.5619, 312.6741],\n",
              "          [346.5666, 284.8170, 405.2224, 314.4591],\n",
              "          [412.3514, 286.2986, 450.9115, 320.0489],\n",
              "          [ 74.3857, 101.4688, 579.1476, 441.5158]], device='cuda:0',\n",
              "         grad_fn=<StackBackward>),\n",
              "  'labels': tensor([ 1, 44, 27, 82, 27, 82, 62, 17, 53, 44, 78, 33, 44, 44, 62, 84, 65, 51,\n",
              "          44, 84, 47, 53, 44, 82, 79, 51, 51,  1, 44, 33,  1, 47, 28, 31, 27, 67,\n",
              "          47,  1, 44, 44, 44, 81, 79], device='cuda:0'),\n",
              "  'scores': tensor([0.8693, 0.7159, 0.6946, 0.6034, 0.5167, 0.4873, 0.3634, 0.3447, 0.3321,\n",
              "          0.2331, 0.2169, 0.2092, 0.2074, 0.1794, 0.1558, 0.1539, 0.1417, 0.1301,\n",
              "          0.1283, 0.1105, 0.1057, 0.1008, 0.0923, 0.0911, 0.0895, 0.0846, 0.0819,\n",
              "          0.0817, 0.0805, 0.0773, 0.0767, 0.0744, 0.0696, 0.0686, 0.0682, 0.0679,\n",
              "          0.0661, 0.0649, 0.0649, 0.0598, 0.0546, 0.0536, 0.0534],\n",
              "         device='cuda:0', grad_fn=<IndexBackward>)},\n",
              " {'boxes': tensor([[212.5397,  64.2023, 563.9282, 358.7718],\n",
              "          [355.1589, 226.9010, 394.5103, 299.8187],\n",
              "          [389.6106,  89.7069, 565.4318, 280.4237],\n",
              "          [ 31.8342, 141.2249, 331.9860, 406.0846],\n",
              "          [505.8641, 118.0132, 577.4388, 238.9388],\n",
              "          [ 48.9423,  52.3993, 567.9708, 441.1093],\n",
              "          [269.1020, 288.9832, 305.5331, 314.1668],\n",
              "          [236.7639, 178.1634, 305.9442, 259.8866],\n",
              "          [227.3062, 120.0427, 242.7734, 138.9593],\n",
              "          [338.5215, 220.8336, 377.9923, 313.5775],\n",
              "          [187.0308,  13.4958, 254.0475,  83.2915],\n",
              "          [197.4345, 300.9328, 606.9046, 453.8034],\n",
              "          [365.9975, 226.3491, 393.0796, 276.2737],\n",
              "          [339.6570, 226.1735, 356.4973, 312.2776],\n",
              "          [296.6670, 292.5830, 333.8354, 310.4262],\n",
              "          [ 48.6918, 261.7969, 128.5480, 354.0468],\n",
              "          [ 64.2551,  53.7829, 594.8115, 415.7347],\n",
              "          [284.8063, 285.2485, 445.4222, 315.1196],\n",
              "          [232.7171, 141.9245, 239.5738, 164.5803],\n",
              "          [ 34.7142, 153.2637, 226.5622, 379.1881],\n",
              "          [470.8498, 388.5547, 492.6794, 422.2319],\n",
              "          [236.4508, 116.4599, 248.5372, 130.9023],\n",
              "          [239.7056,  92.6143, 249.2436, 109.9763],\n",
              "          [189.5545, 161.1655, 290.0090, 386.9644],\n",
              "          [188.5357, 238.6656, 606.9074, 457.8269],\n",
              "          [414.8325, 289.5162, 446.8152, 317.3776],\n",
              "          [364.6156, 284.5240, 428.0466, 315.6868],\n",
              "          [313.9790, 241.6604, 344.0585, 303.8826],\n",
              "          [313.2613, 242.8336, 342.6058, 299.2422],\n",
              "          [ 93.6444, 115.9924, 574.4103, 445.6391],\n",
              "          [ 78.5636, 211.0039, 108.7784, 248.1253],\n",
              "          [428.6737, 386.3780, 463.9395, 426.0912],\n",
              "          [376.0112,  82.6038, 554.4664, 294.0862],\n",
              "          [390.5019,  86.7960, 556.5341, 296.4944],\n",
              "          [466.5657, 104.2762, 579.8484, 279.6210],\n",
              "          [270.7242, 288.7029, 306.7976, 303.0364],\n",
              "          [451.9509, 427.8454, 516.2504, 467.8262],\n",
              "          [231.8021, 103.0909, 458.8400, 315.9155],\n",
              "          [237.7713, 113.1714, 248.8435, 138.4678],\n",
              "          [351.7283, 285.5481, 373.5619, 312.6741],\n",
              "          [346.5666, 284.8170, 405.2224, 314.4591],\n",
              "          [412.3514, 286.2986, 450.9115, 320.0489],\n",
              "          [ 74.3857, 101.4688, 579.1476, 441.5158]], device='cuda:0',\n",
              "         grad_fn=<StackBackward>),\n",
              "  'labels': tensor([ 1, 44, 27, 82, 27, 82, 62, 17, 53, 44, 78, 33, 44, 44, 62, 84, 65, 51,\n",
              "          44, 84, 47, 53, 44, 82, 79, 51, 51,  1, 44, 33,  1, 47, 28, 31, 27, 67,\n",
              "          47,  1, 44, 44, 44, 81, 79], device='cuda:0'),\n",
              "  'scores': tensor([0.8693, 0.7159, 0.6946, 0.6034, 0.5167, 0.4873, 0.3634, 0.3447, 0.3321,\n",
              "          0.2331, 0.2169, 0.2092, 0.2074, 0.1794, 0.1558, 0.1539, 0.1417, 0.1301,\n",
              "          0.1283, 0.1105, 0.1057, 0.1008, 0.0923, 0.0911, 0.0895, 0.0846, 0.0819,\n",
              "          0.0817, 0.0805, 0.0773, 0.0767, 0.0744, 0.0696, 0.0686, 0.0682, 0.0679,\n",
              "          0.0661, 0.0649, 0.0649, 0.0598, 0.0546, 0.0536, 0.0534],\n",
              "         device='cuda:0', grad_fn=<IndexBackward>)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGyEHmofbxIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "c5edca13-4616-4dd6-e6ac-db836bd27865"
      },
      "source": [
        "\n",
        "# For training\n",
        "images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n",
        "labels = torch.randint(1, 91, (4, 11))\n",
        "images = list(image for image in images)\n",
        "targets = []\n",
        "for i in range(len(images)):\n",
        "    d = {}\n",
        "    d['boxes'] = boxes[i]\n",
        "    d['labels'] = labels[i]\n",
        "    targets.append(d)\n",
        "output = model(images, targets)\n",
        "# For inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)\n",
        "\n",
        "# optionally, if you want to export the model to ONNX:\n",
        "torch.onnx.export(model, x, \"faster_rcnn.onnx\", opset_version = 11)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/rpn.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(image_size[1] / g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:467: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "  'incorrect results).', category=RuntimeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/ops/boxes.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/ops/boxes.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/transform.py:217: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  for s, s_orig in zip(new_size, original_size)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/onnx/symbolic_opset9.py:2115: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  \"If indices include negative values, the exported graph will produce incorrect results.\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}